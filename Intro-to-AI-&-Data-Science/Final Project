import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_excel('Regression dataset_Customer-Lifetime-Value-Prediction.xlsx') # Importing the excel dataset
df.head() # Printing out the first 5 rows

df.info() # Printing out the information about the dataset

print("\nThe number of attributes: ", len(df.axes[1])) # Printing out the amount of attributes (19)
print("The number of observations: ", len(df.axes[0])) # Printing out the amount of observations (6817)

df.describe() # Printing out the statistical info about the dataset

# Plotting the Heatmap
df['T_Claims'] = df['T_Claims'].astype(int)
df_num = df.select_dtypes(int)
heatmap = sns.heatmap(df_num.corr(), annot= True)
heatmap.set(title = 'Correlation')
plt.show()

# Plotting the Bar-Plot (#1)
sns.set(style = "darkgrid")
plt.figure(figsize = (7,7))
ax = sns.countplot(x = "M_Status", hue = "State", data = df)

ax.set_xlabel("Marital Status")
ax.set_ylabel("Total Count")
ax.set_title("Marital Status Distribution Across States", fontweight = "bold")
plt.legend(title = "State")
plt.show()

# Plotting the Bar-Plot (#2)
sns.set(style = "darkgrid")
plt.figure(figsize = (7,7))
ax = sns.countplot(x = "Coverage", hue = "Education", data = df)

ax.set_xlabel("Type of Insurance Coverage")
ax.set_ylabel("Total Count")
ax.set_title("Coverage Type Distribution Across Educations", fontweight = "bold")
plt.legend(title = "Education Type")
plt.show()

# Plotting the Pie-Chart (#1)
v_type = df["V_Class"].value_counts()

v_type_data = pd.DataFrame({"Vehicle": v_type}, index = ["Two-Door Car", "Four-Door Car", "SUV", "Luxury Car", "Luxury SUV", "Sports Car"])
v_type_data.plot.pie(y = "Vehicle", figsize = (6, 6), autopct = "%1.1f%%")

plt.legend(bbox_to_anchor = (1.1, 1), loc = 'upper left')
plt.title("A Pie-Chart for Vehicle Type", fontweight = "bold")

# Plotting the Pie-Chart (#2)
sc_type = df["S_Channel"].value_counts()

sc_type_data = pd.DataFrame({"S_Channel": sc_type}, index = ["Agent", "Web", "Branch", "Call Center"])
sc_type_data.plot.pie(y = "S_Channel", figsize = (6, 6), autopct = "%1.1f%%")

plt.legend(bbox_to_anchor = (1.1, 1), loc = 'upper left')
plt.title("A Pie-Chart for the Sales Channel by which the Customer was Acquired", fontweight = "bold")

# Plotting the Par-Plot
df_num = df.select_dtypes(include = "number")
pairplot = sns.pairplot(df_num,hue = "CLV")
plt.show()

# Plotting the Box-Plot (#1)
sns.set(style = "white")
plt.figure(figsize = (7,7))
boxplot = sns.boxplot(x = "State", y = "CLV", data = df, orient="v")

df_num = df.select_dtypes(include = "number")
plt.legend(title = "Boxplot of States and their CLVs")
plt.show()

# Plotting the Box-Plot (#2)
sns.set(style = "white")
plt.figure(figsize = (7,7))
boxplot = sns.boxplot(x = "V_Class", y = "CLV", data = df, orient = "v")

df_num = df.select_dtypes(include = "number")
plt.legend(title = "Boxplot of V_Class and their CLVs")
plt.show()

# Plotting the Histogram
sns.set(style = "whitegrid")
plt.figure(figsize = (7,7))
df_m_claim = sns.histplot(x = "Income", data = df, color = "skyblue", edgecolor = "black")

df_m_claim.set_xlabel("Income")
df_m_claim.set_title("Histogram of Customer Income")
plt.show()

# Preprocessing
# Separating the input values/feature variables from the output value/ target variable
from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder

x = df.iloc[:, 0:18] # Inputs/Features
y = df.iloc[:, 18]   # Output/Target

# Separating the categorical and numerical columns into two different dataframes
categorical_columns = ["State", "Coverage", "Education", "Emp_Status", "Gender", "Loc_Code", "M_Status", "P_Type", "S_Channel", "V_Class", "V_Size"]
df_col = df[categorical_columns] #categorical dataframe
df_num = df.drop(categorical_columns, axis = 1) # Numerical dataframe

# Converting the categorical data to numerical data using the label encoder and a for loop to convert each categorical data one-by-one
for column in df_col:
  enc = LabelEncoder()
  df_col[column] = enc.fit_transform(df[column])

# adding the encoded categorical data to the numerical dataframe
df2 = pd.concat([df_col,df_num],  axis=1)

print(df_col)

Table=[]

from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.linear_model import LinearRegression
from sklearn.svm import LinearSVC, SVR
from sklearn.neural_network import MLPRegressor

for normalization in range(0, 2):
    if normalization == 0:
      # Z-score normalization
      scaler = StandardScaler()
    else:
      # Min-Max normalization
      scaler = MinMaxScaler()

    X = df2.iloc[:, 0:18]
    y = df2.iloc[:, 18].values.reshape(-1, 1)  # Ensure y is 2D for scaling
    X = scaler.fit_transform(X)
    y = scaler.fit_transform(y).ravel()  # Flatten y back to 1D after scaling

    # Data Splitting, Model training loop and evaluation
    for r in [1, 20, 40]:  # Loop for random state Parameters
        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=r)  # Adjusted train size
        R_models = [LinearRegression(), SVR(kernel='linear'), SVR(kernel='poly'), SVR(kernel='rbf'), MLPRegressor(max_iter=1000000, random_state=r)]
        for model in R_models:
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)


            MSE = mean_squared_error(y_test, y_pred)
            R_2 = r2_score(y_test, y_pred)


            Table.append({'Normalization': normalization, 'Regression Model': model.__class__.__name__, 'Random_State': r, 'MSE': round(MSE, 2), 'R2_score': round(R_2, 2)})

# Taking the results and adding them to a separate data frame
rst_df = pd.DataFrame(Table)

# Finding the average for each of models after resetting their index
average_MSE = rst_df.groupby(['Normalization', "Regression Model"])['MSE'].mean().reset_index()
average_R2 = rst_df.groupby(['Normalization', "Regression Model"])['R2_score'].mean().reset_index()

# Printing out the averages
print("\nAverage MSE by Model:", average_MSE)
print("Average R2 by Model:", average_R2)
